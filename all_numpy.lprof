Wrote profile results to KDE.py.lprof
Timer unit: 1e-06 s

Total time: 22.3171 s
File: KDE.py
Function: eval_KDE at line 7

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     7                                           @profile
     8                                           # compute the mean log probability over the test data
     9                                           def eval_KDE(train_set, test_set, best_sigma):
    10                                               # compute the constant terms of the likelihood 
    11         1          6.0      6.0      0.0      denom = -1*2.0*math.pow(best_sigma,2)
    12         1          3.0      3.0      0.0      norm = -1.0/2 * math.log(2*math.pi*math.pow(best_sigma,2))
    13         1          3.0      3.0      0.0      prior = math.log(1.0/train_set.shape[0])
    14         1          0.0      0.0      0.0      shift_constant = 0
    15                                           
    16                                               # 
    17         1          1.0      1.0      0.0      mean_log_prob = 0.0
    18                                               
    19                                               # for each example in test compute the likelihood - average 
    20                                               # for test_ex in tqdm(test_set):
    21       101        191.0      1.9      0.0      for test_ex in test_set[:100,:]:
    22                                                   # compute the squared distance between the test vector and each example in the train matrix
    23       100   10729707.0 107297.1     48.1          cond_prob_features = np.square(np.subtract(train_set, test_ex))
    24                                           
    25                                                   # divide the distances by the denominator
    26       100   10320328.0 103203.3     46.2          cond_prob_features_norm = np.subtract(np.true_divide(cond_prob_features, denom), norm)
    27                                           
    28                                                   # add the probabilities over the features
    29       100    1207185.0  12071.9      5.4          cond_prob_features = np.sum(cond_prob_features_norm, axis=1)
    30                                           
    31       100        444.0      4.4      0.0          assert cond_prob_features.shape == (train_set.shape[0], )
    32                                           
    33                                                   # add the prior
    34       100       3127.0     31.3      0.0          cond_prob_features = np.add(cond_prob_features, prior)
    35                                           
    36       100       5549.0     55.5      0.0          shift_constant = np.max(np.abs(cond_prob_features)) 
    37                                           
    38                                                   # raise the values to exp, while shifting the values to ensure no overflow occurs
    39       100      47836.0    478.4      0.2          likelihoods = np.exp(np.subtract(cond_prob_features, shift_constant))
    40                                           
    41       100       2477.0     24.8      0.0          mean_log_prob += np.add(math.log(np.sum(likelihoods)), shift_constant)
    42                                                   
    43       100        275.0      2.8      0.0          assert mean_log_prob < math.inf
    44                                           
    45         1          3.0      3.0      0.0      return mean_log_prob/test_set.shape[0]